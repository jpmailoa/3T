{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d802637b-fcb4-43eb-9d82-d047d304424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used the attached jupyter notebook from the work of 'Ricci-Lopez, Joel, et al. \n",
    "# \"Improving structure-based virtual screening with ensemble docking and machine learning.\" \n",
    "# Journal of Chemical Information and Modeling 61.11 (2021): 5362-5376.'\n",
    "# These jupyter notebooks could be found in https://github.com/jRicciL/ML-ensemble-docking\n",
    "# For example, for CDK2, jupyter notebooks in cdk2/5_Machine_Learning/ were adopted \n",
    "# and modified here for classification evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0527b462-b63a-4ff1-a775-43f2bfe923c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/aidd/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.1, the latest is 0.5.2.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import seaborn as sns\n",
    "import glob\n",
    "sys.path.append('./')\n",
    "from helper_modules.run_or_load import run_or_load_joblib\n",
    "from helper_modules.plotting_metrics import PlotMetric\n",
    "from helper_modules.friedman_and_nemenyi_test import *\n",
    "%run helper_modules/Helper_functions_for_nRepeats_x_kCV.ipynb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af4c3e7-93dc-4dbb-923e-438f4a06cf4e",
   "metadata": {},
   "source": [
    "## Construct the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15ef9f08-a6bd-49c8-adbb-739ec08d2336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# dummy classifier\n",
    "hyparams = {'strategy': \"stratified\"}\n",
    "dclf = DummyClassifier(**hyparams)\n",
    "\n",
    "# logistic regression\n",
    "# parameters for CDK2 and FXA\n",
    "hyparams = {'C'       : 0.01, \n",
    "            'penalty' : 'l2', \n",
    "            'solver'  : 'lbfgs', \n",
    "            'max_iter': 400}\n",
    "lr_cdk2 = LogisticRegression(**hyparams)\n",
    "lr_fxa = LogisticRegression(**hyparams)\n",
    "# parameters for HSP90\n",
    "hyparams_hsp90 = {'C'        : 1.0, \n",
    "            'penalty'  : 'l2', \n",
    "            'solver'   : 'lbfgs', \n",
    "            'max_iter' : 400}\n",
    "lr_hsp90 = LogisticRegression(**hyparams)\n",
    "\n",
    "# XGBoost\n",
    "# parameters for CDK2\n",
    "hyparams_cdk2 = {'subsample'        : 0.5, \n",
    "            'n_estimators'     : 200, \n",
    "            'max_depth'        : 20, \n",
    "            'learning_rate'    : 0.05,\n",
    "            'alpha'            : 0.01,\n",
    "            'gamma'            : 0.01, \n",
    "            'colsample_bytree' : 0.5,\n",
    "            'eval_metric'      : 'logloss',\n",
    "            'use_label_encoder': False\n",
    "           }\n",
    "xgb_cdk2 = XGBClassifier(**hyparams_cdk2)\n",
    "# parameters for FXA\n",
    "hyparams_fxa = {\n",
    "    'subsample'        : 0.5, \n",
    "    'n_estimators'     : 200, \n",
    "    'max_depth'        : 10, \n",
    "    'learning_rate'    : 0.1,\n",
    "    'alpha'            : 0.5,\n",
    "    'gamma'            : 1, \n",
    "    'colsample_bytree' : 1,\n",
    "    'eval_metric'      : 'logloss',\n",
    "    'use_label_encoder': False\n",
    "}\n",
    "xgb_fxa = XGBClassifier(**hyparams_fxa)\n",
    "# parameters for HSP90\n",
    "hyparams_hsp90 = {\n",
    "     'subsample'        : 0.6,\n",
    "     'n_estimators'     : 500,\n",
    "     'max_depth'        : 5,\n",
    "     'learning_rate'    : 0.05,\n",
    "     'gamma'            : 0.01,\n",
    "     'colsample_bytree' : 0.5,\n",
    "     'alpha'            : 0.1,\n",
    "     'eval_metric'      :   'logloss',\n",
    "     'use_label_encoder': False\n",
    "    }\n",
    "\n",
    "xgb_hsp90 = XGBClassifier(**hyparams_hsp90)\n",
    "\n",
    "# ML Classifiers\n",
    "# for CDK2\n",
    "ml_classifiers_cdk2 = {\n",
    "    'ml_lr'  : lr_cdk2,\n",
    "    'ml_xgb' : xgb_cdk2,\n",
    "    'ml_dclf': dclf\n",
    "}\n",
    "estimators_cdk2 = {**ml_classifiers_cdk2}\n",
    "# for FXA\n",
    "ml_classifiers_fxa = {\n",
    "    'ml_lr'  : lr_fxa,\n",
    "    'ml_xgb' : xgb_fxa,\n",
    "    'ml_dclf': dclf\n",
    "}\n",
    "estimators_fxa = {**ml_classifiers_fxa}\n",
    "# for HSP90\n",
    "ml_classifiers_hsp90 = {\n",
    "    'ml_lr'  : lr_hsp90,\n",
    "    'ml_xgb' : xgb_hsp90,\n",
    "    'ml_dclf': dclf\n",
    "}\n",
    "estimators_hsp90 = {**ml_classifiers_hsp90}\n",
    "\n",
    "# all estimators\n",
    "estimators = {'CDK2':estimators_cdk2,\n",
    "              'FXA':estimators_fxa,\n",
    "              'HSP90':estimators_hsp90}\n",
    "\n",
    "sbvs_names = {'ml_lr': 'LR', 'ml_xgb': 'GBT', 'ml_dclf': 'DClf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f79601-abd6-429f-b81e-77bf24570275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a file to ommit repeate the analysis\n",
    "@run_or_load_joblib\n",
    "def nk_rep_cross_validation_SAVE(filename, **kwargs):\n",
    "    return nk_rep_cross_validation(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca6379-6eb8-4684-82d5-6a91261f4474",
   "metadata": {},
   "source": [
    "## 30x4 cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c490e3a1-f3c6-407f-9c6a-b4e59dc39be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30x4 cross validation for different estimators\n",
    "def get_cv30x4(X, y, estimators, pro, cache_name, RANDOM_STATE=1):\n",
    "    R_a = round(y.sum() / len(y), 4)\n",
    "    print(f'Ratio of actives {y.sum()}/{len(y)}:', R_a)\n",
    "    metrics = dict(\n",
    "        # AUC-ROC\n",
    "        roc_auc   = {'metric_name': 'roc_auc'},\n",
    "        # Normalized Enrichment Factor\n",
    "        nef_Ra = {'metric_name': 'ef', \n",
    "                  'fraction'   : R_a, \n",
    "                  'method'     : 'normalized'}\n",
    "        )\n",
    "    \n",
    "    n_repeats = 30\n",
    "    n_splits  = 4\n",
    "    evaluation_name = f'{n_repeats}x{n_splits}cv'\n",
    "    cv30x4, y_preds, splits = nk_rep_cross_validation_SAVE(\n",
    "        filename = cache_name,\n",
    "        estimators = estimators, \n",
    "        X = X,\n",
    "        y = y, \n",
    "        metrics   = metrics, \n",
    "        n_repeats = n_repeats, \n",
    "        n_splits  = n_splits,\n",
    "        y_preds_return = True,\n",
    "        random_state   = RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    # Rename columns \n",
    "    cv30x4 = cv30x4.rename(columns = sbvs_names)\n",
    "    return cv30x4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea36ac-4e7f-47b1-af2a-d95027121a3b",
   "metadata": {},
   "source": [
    "### Using the features from Ricci et al. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e97066-ff4e-4af4-9e52-f5ca4bdaed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files CDK2/df_DkSc_results_COCRYS_CSAR_DEKOIS_DUD.pkl\n",
      "Ratio of actives 415/3466: 0.1197\n",
      "File loaded: CDK2/Ricci_original\n",
      "Input files FXA/df_DkSc_results_COCRYS_DEKOIS_DUD.pkl\n",
      "Ratio of actives 300/6233: 0.0481\n",
      "File loaded: FXA/Ricci_original\n",
      "Input files HSP90/df_DkSc_results_COCRYS_DEKOIS_DUD.pkl\n",
      "Ratio of actives 256/2302: 0.1112\n",
      "File loaded: HSP90/Ricci_original\n"
     ]
    }
   ],
   "source": [
    "for pro in ['CDK2', 'FXA', 'HSP90']:\n",
    "    file_name = [x for x in glob.glob(f'{pro}/df_DkSc*.pkl')][0]\n",
    "    print('Input files',file_name)\n",
    "    df_dk_res = pd.read_pickle(file_name)\n",
    "    # Extract the features columns: Docking scores\n",
    "    X = df_dk_res.drop('activity', axis = 1).values\n",
    "    # Extract the response variable: Activity\n",
    "    y = df_dk_res['activity'].values\n",
    "    cache_name = pro+'/Ricci_original'\n",
    "    estimator = estimators[pro]\n",
    "    out = get_cv30x4(X, y, estimator, pro, cache_name)\n",
    "    out.to_csv(f'{pro}/{pro}_Ricci_ML.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605360c2-8557-49a7-83c4-bdffb51c3086",
   "metadata": {},
   "source": [
    "### Using features from 3T for 20A pocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ad35d6-7546-41a7-9326-50cde544a64e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files CDK2/CDK2_scrambled_training_data.pkl\n",
      "Ratio of actives 442.0/3763: 0.1175\n",
      "File loaded: CDK2/3T\n",
      "Input files FXA/FXA_scrambled_training_data.pkl\n",
      "Ratio of actives 289.0/7191: 0.0402\n",
      "File loaded: FXA/3T\n",
      "Input files HSP90/HSP90_scrambled_training_data.pkl\n",
      "Ratio of actives 298.0/2452: 0.1215\n",
      "File loaded: HSP90/3T\n"
     ]
    }
   ],
   "source": [
    "for pro in ['CDK2', 'FXA', 'HSP90']:\n",
    "    file_name = f'{pro}/{pro}_scrambled_training_data.pkl'\n",
    "    print('Input files',file_name)\n",
    "    df_dk_res = pd.read_pickle(file_name)\n",
    "    X = df_dk_res['X']\n",
    "    X[X > 20] = 20.0\n",
    "    X[X < -20] = -20.0\n",
    "    y = df_dk_res['y']\n",
    "    X = X.astype(float)\n",
    "    y = y.astype(float)    \n",
    "    cache_name = pro+'/3T'\n",
    "    estimator = estimators[pro]\n",
    "    out = get_cv30x4(X, y, estimator, pro, cache_name)\n",
    "    out.to_csv(f'{pro}/{pro}_scrambled_3T_ML.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f71b347-72cb-445f-bcdf-83ca7b44dc79",
   "metadata": {},
   "source": [
    "### Using features from 3T for 25A pocket in CDK2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff5b5078-ba0d-4be6-b1b8-4f06e4b71b87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files CDK2/CDK2_25A_scrambled_training_data.pkl\n",
      "Ratio of actives 442.0/3764: 0.1174\n",
      "File loaded: CDK2/3T_25A\n"
     ]
    }
   ],
   "source": [
    "pro = 'CDK2'\n",
    "file_name = f'{pro}/{pro}_25A_scrambled_training_data.pkl'\n",
    "print('Input files',file_name)\n",
    "df_dk_res = pd.read_pickle(file_name)\n",
    "X = df_dk_res['X']\n",
    "X[X > 20] = 20.0\n",
    "X[X < -20] = -20.0\n",
    "y = df_dk_res['y']\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)    \n",
    "cache_name = pro+'/3T_25A'\n",
    "estimator = estimators[pro]\n",
    "out = get_cv30x4(X, y, estimator, pro, cache_name)\n",
    "out.to_csv(f'{pro}/{pro}_25A_scrambled_3T_ML.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78178f8c-bc46-4faa-9b6c-5a252d80f472",
   "metadata": {},
   "source": [
    "### Using features from 3T for rigid pocket in HSP90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd71593-21ed-4f85-97ad-2a59357fb8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files HSP90/HSP90_rigid_scrambled_training_data.pkl\n",
      "Ratio of actives 298.0/2452: 0.1215\n",
      "File loaded: HSP90/3T_rigid\n"
     ]
    }
   ],
   "source": [
    "pro = 'HSP90'\n",
    "file_name = f'{pro}/{pro}_rigid_scrambled_training_data.pkl'\n",
    "print('Input files',file_name)\n",
    "df_dk_res = pd.read_pickle(file_name)\n",
    "X = df_dk_res['X']\n",
    "X[X > 20] = 20.0\n",
    "X[X < -20] = -20.0\n",
    "y = df_dk_res['y']\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)    \n",
    "cache_name = pro+'/3T_rigid'\n",
    "estimator = estimators[pro]\n",
    "out = get_cv30x4(X, y, estimator, pro, cache_name)\n",
    "out.to_csv(f'{pro}/{pro}_rigid_scrambled_3T_ML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b0f2d-fb6e-446e-97cf-24b1bc749c07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
