{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcbafa85-ed86-4ba5-854d-cdddcead8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a99bd19-edb7-4d02-8b89-5602f0a56d45",
   "metadata": {},
   "source": [
    "## Postprocess for 3T generated structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c608097a-e402-4bea-b054-c41bb97b9dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cif2gro import cif2gro\n",
    "from match_mol2_coordinates_from_gro import get_mol2_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1546bf6-3c3c-4e79-8f70-217f9478304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first converted all .cif files into .gro files for further analyses\n",
    "for pro in ['CDK2', 'FXA', 'HSP90']:\n",
    "    l = sorted([x for x in glob.glob(f'{pro}/3T_processed/*/step*.cif')])\n",
    "    for i in l:\n",
    "        ref = '/'.join(i.split('/')[:-1])+'/complex.gro'\n",
    "        out = i.replace('.cif', '.gro')\n",
    "        cif2gro(ref, i, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd917bf-0256-4fed-af78-efdc3ea2a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we split the .gro files to get ligand .mol2 files\n",
    "for pro in ['CDK2', 'FXA', 'HSP90']:\n",
    "    l = sorted([x for x in glob.glob(f'{pro}/3T_processed/*/*.gro')])\n",
    "    for i in l:\n",
    "        mol2_file = f'{pro}/ligand_processed/'+i.split('/')[-2]+'.mol2'\n",
    "        out = i.replace('.gro', '.mol2')\n",
    "        get_mol2_coord(mol2_file, i, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93018284-5354-4146-8234-58ce6e763d72",
   "metadata": {},
   "source": [
    "## Calculate RMSD to initial cocrystal structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a42fe7-aa80-454b-8b20-9752e36b3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cal_RMSD import cal_RMSD\n",
    "from get_energy import get_3T_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad4a8a4b-f2bb-47bf-92fb-4b341e82ce96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing CDK2/3T_processed/cocry_1jsv_U55_LIG_dock_1fin_1/\n",
      "processing CDK2/3T_processed/cocry_2iw8_4SP_LIG_dock_1fin_1/\n",
      "processing CDK2/3T_processed/dekois2_decoy_1_dock_1fin_1/\n",
      "processing CDK2/3T_processed/dekois2_ligand_1_dock_1fin_1/\n",
      "processing CDK2/3T_processed/dude_decoy_1_dock_1fin_1/\n",
      "processing CDK2/3T_processed/dude_ligand_1_dock_1fin_1/\n",
      "processing FXA/3T_processed/cocry_2d1j_D01_LIG_dock_1ezq_1/\n",
      "processing FXA/3T_processed/cocry_2d1j_D01_LIG_dock_1ezq_2/\n",
      "processing FXA/3T_processed/cocry_2y82_930_LIG_dock_1ezq_1/\n",
      "processing FXA/3T_processed/dekois2_decoy_1_dock_1ezq_1/\n",
      "processing FXA/3T_processed/dekois2_ligand_1_dock_1ezq_1/\n",
      "processing FXA/3T_processed/dude_decoy_1_dock_1ezq_1/\n",
      "processing FXA/3T_processed/dude_ligand_1_dock_1ezq_1/\n",
      "processing HSP90/3T_processed/cocry_1byq_ADP_LIG_dock_1uyg_1/\n",
      "processing HSP90/3T_processed/cocry_2fwy_H64_LIG_dock_1uyg_1/\n",
      "processing HSP90/3T_processed/cocry_2fwy_H64_LIG_dock_1uyg_2/\n",
      "processing HSP90/3T_processed/cocry_2fwy_H64_LIG_dock_1uyg_3/\n",
      "processing HSP90/3T_processed/dekois2_decoy_11_dock_1uyg_1/\n",
      "processing HSP90/3T_processed/dekois2_ligand_11_dock_1uyg_1/\n",
      "processing HSP90/3T_processed/dude_decoy_11_dock_1uyg_1/\n",
      "processing HSP90/3T_processed/dude_ligand_11_dock_1uyg_1/\n"
     ]
    }
   ],
   "source": [
    "# pre-defined pockets of the three proteins\n",
    "pocket_map = {'CDK2': '6-21+29-36+61-68+76-92+125-150',\n",
    "              'FXA': '41-46+76-90+159-168+171-186+205-216',\n",
    "              'HSP90': '93-100+101-121+131-144+145-153'}\n",
    "ref_lig_map = {'CDK2':'1fin', 'FXA': '1ezq', 'HSP90': '1uyg'}\n",
    "\n",
    "# calculate the RMSD of the #T generated ligand poses to the cocrystal poses\n",
    "for pro in ['CDK2', 'FXA', 'HSP90']:\n",
    "    l = sorted([x for x in glob.glob(f'{pro}/3T_processed/*/')])\n",
    "    for i in l:\n",
    "        print(f'processing {i}')\n",
    "        if 'cocry' in i:\n",
    "            PDB = i.split('/')[-2].split('_')[1]\n",
    "            cal_RMSD(i,PDB,pro+'/analyses/', pro, pocket_map[pro], cocry=1)\n",
    "        else:\n",
    "            PDB = i.split('/')[-2].split('_')[-2]\n",
    "            cal_RMSD(i,PDB,pro+'/analyses/', pro, pocket_map[pro], cocry=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "620e9734-b4b5-43f2-97b7-bb53dc521078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge RMSD calculation for multiple conformers if available\n",
    "\n",
    "for pro in ['CDK2', 'FXA', 'HSP90']:\n",
    "    PATHs = sorted(list(set([x.split(f'dock_{ref_lig_map[pro]}')[0] \n",
    "                             for x in glob.glob(f'{pro}/analyses/*_*_RMSD_backbone.csv')])))\n",
    "    for PATH in PATHs:\n",
    "        all_files = sorted([x for x in glob.glob(f'{pro}/analyses/*_*_RMSD_backbone.csv')\n",
    "                          if PATH in x])\n",
    "        idx = [x.split('/')[-1].split('_')[-3] for x in all_files]\n",
    "        all_files = [pd.read_csv(x, index_col = 0) for x in all_files]\n",
    "        all_index = [x.index.tolist() for x in all_files]\n",
    "        all_index = [[y.replace('.gro', '_'+i) for y in x] \n",
    "                     for x,i in zip(all_index, idx)]\n",
    "        for i,j in zip(all_files, all_index):\n",
    "            i.index = j\n",
    "        o = pd.concat(all_files, axis = 0)\n",
    "        o.to_csv(PATH+f'dock_{ref_lig_map[pro]}_RMSD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95c2166c-44c5-4020-8744-fbb64e3318af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of CDK2 RMSD features is  (36, 308)\n",
      "The shape of FXA RMSD features is  (36, 106)\n",
      "The shape of HSP90 RMSD features is  (36, 223)\n"
     ]
    }
   ],
   "source": [
    "# Here we just show the examples of processing the RMSDs. The raw RMSDs for all \n",
    "# ligands mentioned in the paper could be found in the three folder entitled:\n",
    "# CDK2/CDK2_RMSD_features_raw.tsv\n",
    "# FXA/FXA_RMSD_features_raw.tsv\n",
    "# HSP90/HSP90_RMSD_features_raw.tsv\n",
    "\n",
    "for pro in ['CDK2', 'FXA', 'HSP90']:\n",
    "    dt = pd.read_csv(f'{pro}/{pro}_RMSD_features_raw.tsv', \n",
    "                     index_col = 0, sep = '\\t')\n",
    "    print(f'The shape of {pro} RMSD features is ', dt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f2c83-8ce6-4651-813d-cac9e86f4cd1",
   "metadata": {},
   "source": [
    "## Get the minimization energy and vina scores for the 3T minimized structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28cba46b-7d06-411b-83ff-6e1c6f5f1249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the 3T minimized energy\n",
    "for pro in ['CDK2', 'FXA', 'HSP90']:\n",
    "    path = sorted([x.split(f'dock_{ref_lig_map[pro]}')[0][:-1].split('/')[-1] \n",
    "                   for x in glob.glob(f'{pro}/3T_processed/*/')])\n",
    "    for i in path:\n",
    "        get_3T_energy(i, pro+'/analyses/', pro+'/3T_processed/', ref_lig_map[pro])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f2828a-8391-4cfc-ab1a-389f03799e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescore the 3T minimized structures with smina. We recommended to do this in parallel.\n",
    "\n",
    "for pro in ['CDK2', 'FXA', 'HSP90']:\n",
    "    l = sorted([x for x in glob.glob(f'{pro}/3T_processed/*/*.gro')])\n",
    "    cc = []\n",
    "    for i in l:\n",
    "        if 'cocry' in i:\n",
    "            c = ' '.join(['smina', '-l', i.replace('.gro', '.mol2'), \n",
    "                          '-r', i.replace('.gro', '_0.pdb'),\n",
    "                                '--score_only', '>', i.replace('.gro', '.score'), '\\n'])\n",
    "            cc.append(c)\n",
    "        else:\n",
    "            c = ' '.join(['smina', '-l', i.replace('.gro', '.mol2'), \n",
    "                          '-r', i.replace('.gro', '.pdb'),\n",
    "                                '--score_only', '>', i.replace('.gro', '.score'), '\\n'])\n",
    "            cc.append(c)\n",
    "    f = open(f'{pro}/rescore.sh','w')\n",
    "    for i in cc:\n",
    "        f.write(i)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b572e947-c491-4370-9eee-ab2283371307",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat CDK2/rescore.sh | parallel -j 16 {}\n",
    "cat FXA/rescore.sh | parallel -j 16 {}\n",
    "cat HSP90/rescore.sh | parallel -j 16 {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ec54161-9d3a-4c49-9cb8-7c1d16227f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the rescores into one file in each folder \n",
    "for pro in ['CDK2', 'FXA', 'HSP90']:\n",
    "    PATHs = [x for x in glob.glob(f'{pro}/3T_processed/*/')]   \n",
    "    for PATH in PATHs:\n",
    "        files = sorted([x for x in glob.glob(PATH+'*.gro')])\n",
    "        scores = []\n",
    "        for i in files:\n",
    "            try:\n",
    "                score = [x for x in open(i.replace('.gro', '.score'), 'r') \n",
    "                         if x.startswith('Affinity')]\n",
    "                score = [float(x[:-1].replace('Affinity:','').replace('(kcal/mol)','').strip()) \n",
    "                         for x in score][0]\n",
    "                scores.append(score)\n",
    "            except:\n",
    "                files = [x for x in files if x != i]\n",
    "                print(i, 'failed')\n",
    "        if scores != []:\n",
    "            scores = pd.DataFrame(scores)\n",
    "            idx = [x.split('/')[-1].replace('.gro', '')+'_%d'%(int(PATH.split('/')[-2].split('_')[-1])) \n",
    "                   for x in files]\n",
    "            scores.index = idx\n",
    "            scores.columns = [PATH.split('/')[-2]]\n",
    "            scores.to_csv(PATH+'rescore.csv')\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "# merge all rescores for a ligand into a file in analyses/\n",
    "for pro in ['CDK2', 'FXA', 'HSP90']:\n",
    "    PATHs = sorted(list(set([x.split(f'dock_{ref_lig_map[pro]}')[0][:-1].split('/')[-1]\n",
    "                    for x in glob.glob(f'{pro}/3T_processed/*/')])))\n",
    "    for PATH in PATHs:\n",
    "        p = sorted([x for x in glob.glob(f'{pro}/3T_processed/'+PATH+'_*/rescore.csv')])\n",
    "        s = [pd.read_csv(x, index_col = 0) for x in p]\n",
    "        for i in s:\n",
    "            i.columns = [PATH]\n",
    "        s = pd.concat(s, axis = 0)\n",
    "        s.to_csv(f'{pro}/analyses/{PATH}_dock_{ref_lig_map[pro]}_rescore.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a642a9-a1c6-4414-8526-3fe460560bf6",
   "metadata": {},
   "source": [
    "## Prepare the features for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d7aa7fc-6696-4fa8-b47c-ef11aadb9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first used the 12 vina scores of the first rotamer of a ligand as part of the features\n",
    "for pro in ['CDK2', 'FXA', 'HSP90']:\n",
    "    PATHs = sorted([x for x in glob.glob(f'{pro}/analyses/*_rescore.csv')])\n",
    "    idx = ['complex_1', 'step1_200.xyz_1',\n",
    "           'step2_200_2000_5.0_16930.xyz_1', 'step2_200_2000_5.0_2177.xyz_1',\n",
    "           'step2_200_2000_5.0_27766.xyz_1', 'step2_200_2000_5.0_28005.xyz_1',\n",
    "           'step2_200_2000_5.0_4094.xyz_1', 'step2_200_2000_5.0_47873.xyz_1',\n",
    "           'step2_200_2000_5.0_77285.xyz_1', 'step2_200_2000_5.0_85412.xyz_1',\n",
    "           'step2_200_2000_5.0_86398.xyz_1', 'step2_200_2000_5.0_86498.xyz_1']\n",
    "    files = [pd.read_csv(x, index_col = 0) for x in PATHs]\n",
    "    files_ = []\n",
    "    for x in files:\n",
    "        try:\n",
    "            files_.append(x.loc[idx])\n",
    "        except:\n",
    "            pass\n",
    "    out = pd.concat(files_, axis = 1)\n",
    "    out.to_csv(f'{pro}/{pro}_smina_features.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7228b317-5da9-4d74-b71e-1032c5c45620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of CDK2 smina features is  (12, 3765)\n",
      "The shape of FXA smina features is  (12, 7191)\n",
      "The shape of HSP90 smina features is  (12, 2452)\n"
     ]
    }
   ],
   "source": [
    "# Here we just show the examples of getting smina scores. The raw smina scores for all \n",
    "# ligands mentioned in the paper could be found in the three folder entitled:\n",
    "# CDK2/CDK2_smina_features_raw.tsv\n",
    "# FXA/FXA_smina_features_raw.tsv\n",
    "# HSP90/HSP90_smina_features_raw.tsv\n",
    "\n",
    "for pro in ['CDK2', 'FXA', 'HSP90']:\n",
    "    dt = pd.read_csv(f'{pro}/{pro}_smina_features_raw.tsv', \n",
    "                     index_col = 0, sep = '\\t')\n",
    "    print(f'The shape of {pro} smina features is ', dt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15f81473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def compile_score(folder,out_tag):\n",
    "    in_csv = os.path.join(folder,out_tag+'_smina_features_raw.tsv')\n",
    "    tab = pd.read_csv(in_csv, nrows=1, sep='\\t').shape[1]\n",
    "    comma = pd.read_csv(in_csv, nrows=1, sep=',').shape[1]\n",
    "    if tab > comma:\n",
    "        data = pd.read_csv(in_csv,sep='\\t',low_memory=False)\n",
    "    else:\n",
    "        data = pd.read_csv(in_csv,sep=',',low_memory=False)\n",
    "    columns = data.columns\n",
    "    tags = data[ data.columns[0] ]\n",
    "    tags = [tags.values[i] for i in range(len(tags))]\n",
    "    complexes = [data.columns[i] for i in range(1, len(data.columns))]\n",
    "    data = data.values[:,1:]\n",
    "    out_dict = dict()\n",
    "    out_dict['complex'] = complexes\n",
    "    out_dict['dock_score'] = data\n",
    "    out_dict['tags'] = tags\n",
    "    pickle.dump(out_dict, open( os.path.join(folder,out_tag+'_3T_score.pkl'), 'wb'))\n",
    "    return\n",
    "\n",
    "# Next we compile the smina score values to make them more convenient for subsequent processing\n",
    "compile_score('CDK2','CDK2')\n",
    "compile_score('CDK2','CDK2_25A')\n",
    "compile_score('HSP90','HSP90')\n",
    "compile_score('HSP90','HSP90_rigid')\n",
    "compile_score('FXA','FXA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17565c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDK2/CDK2_scrambled_training_data.pkl : (n_sample,n_feature) = (3763, 232)\n",
      "CDK2/CDK2_25A_scrambled_training_data.pkl : (n_sample,n_feature) = (3764, 232)\n",
      "HSP90/HSP90_scrambled_training_data.pkl : (n_sample,n_feature) = (2452, 232)\n",
      "HSP90/HSP90_rigid_scrambled_training_data.pkl : (n_sample,n_feature) = (2452, 232)\n",
      "FXA/FXA_scrambled_training_data.pkl : (n_sample,n_feature) = (7191, 232)\n",
      "\n",
      "Smina score and energy features successfully merged\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "def merge_features(score_pkl, E_pkl, training_pkl, suffix_tag):\n",
    "    # score file and energy file has slightly different complex names\n",
    "    # this difference is suffix_tag, which was previously done manually during raw data generation...\n",
    "    # we will merge the features while making sure we take care of these different naming conventions\n",
    "    random_seed = 12345\n",
    "    data = pickle.load(open(score_pkl,'rb'))\n",
    "    complexes = data['complex']\n",
    "    classes = []\n",
    "    for i in range(len(complexes)):\n",
    "        words = complexes[i].split('_')\n",
    "        if words[0] == 'cocry':\n",
    "            classes.append(1)\n",
    "        elif words[1] == 'ligand':\n",
    "            classes.append(1)\n",
    "        else:\n",
    "            classes.append(0)\n",
    "    classes = np.array(classes)\n",
    "    \n",
    "    X = data['dock_score'].T\n",
    "    y = classes\n",
    "    # Remove nan entries, there are two such columns during the rescoring of CDK2 with 20A pocket\n",
    "    nan_indices = np.argwhere(X != X)\n",
    "    excluded_indices = list(set(nan_indices[:,0]))\n",
    "    included_indices = [i for i in range(X.shape[0])]\n",
    "    for idx in excluded_indices: \n",
    "        included_indices.remove(idx)\n",
    "    X = X[included_indices,:]\n",
    "    y = y[included_indices]\n",
    "    score_complexes = [complexes[i] for i in included_indices]\n",
    "    \n",
    "    data = pickle.load(open(E_pkl,'rb'))\n",
    "    energy_complexes = data['complex']\n",
    "    energy = data['E_binding']\n",
    "    seed_list = data['seed']\n",
    "    indices = []\n",
    "    for i in range(len(score_complexes)):\n",
    "        name = score_complexes[i] + suffix_tag\n",
    "        idx = energy_complexes.index(name)\n",
    "        indices.append(idx)\n",
    "    energy_complexes = [energy_complexes[i] for i in indices]\n",
    "    energy = energy[indices]\n",
    "    energy = energy.reshape([energy.shape[0],-1])\n",
    "    \n",
    "    # Structures with high smina scores or energies occur, so just set these values to 0\n",
    "    bad_score_idx = np.where(X >= 0)\n",
    "    bad_score_idx = [(bad_score_idx[0][i],bad_score_idx[1][i]) for i in range(len(bad_score_idx[0]))]\n",
    "    bad_energy_idx = np.where(energy >= 100)\n",
    "    bad_energy_idx = [(bad_energy_idx[0][i],bad_energy_idx[1][i]) for i in range(len(bad_energy_idx[0]))]\n",
    "    for idx in bad_score_idx:\n",
    "        X[idx[0],idx[1]] = 0\n",
    "    for idx in bad_energy_idx:\n",
    "        energy[idx[0],idx[1]] = 0\n",
    "    X = np.concatenate((X, energy), axis=1)\n",
    "    \n",
    "    # Dump merged features to training_pkl after scrambling data indices for classification training\n",
    "    n = X.shape[0]\n",
    "    new_idx = [i for i in range(n)]\n",
    "    random.seed(random_seed)\n",
    "    random.shuffle(new_idx)\n",
    "    out = dict()\n",
    "    out['X'] = X[new_idx,:]\n",
    "    out['y'] = y[new_idx]\n",
    "    out['complex_name'] = [score_complexes[i] for i in new_idx]\n",
    "    pickle.dump(out, open(training_pkl,'wb'))\n",
    "    \n",
    "    print(training_pkl,':','(n_sample,n_feature) =',X.shape)\n",
    "    return\n",
    "\n",
    "# Create training pickle files from smina score and energy files\n",
    "E_dir = '../2_structure_generation/Energies/Downsampled_Full_Dataset/'\n",
    "out_tag = '_scrambled_training_data.pkl'\n",
    "merge_features('CDK2/CDK2_3T_score.pkl', E_dir+'CDK2_3T_energy.pkl', 'CDK2/CDK2'+out_tag, suffix_tag='_1')\n",
    "merge_features('CDK2/CDK2_25A_3T_score.pkl', E_dir+'CDK2_25A_3T_energy.pkl', 'CDK2/CDK2_25A'+out_tag, suffix_tag='_dock_1FIN_1')\n",
    "merge_features('HSP90/HSP90_3T_score.pkl', E_dir+'HSP90_3T_energy.pkl', 'HSP90/HSP90'+out_tag, suffix_tag='_dock_1uyg_1')\n",
    "merge_features('HSP90/HSP90_rigid_3T_score.pkl', E_dir+'HSP90_rigid_3T_energy.pkl', 'HSP90/HSP90_rigid'+out_tag, suffix_tag='_dock_1uyg_1')\n",
    "merge_features('FXA/FXA_3T_score.pkl', E_dir+'FXA_3T_energy.pkl', 'FXA/FXA'+out_tag, suffix_tag='_dock_1ezq_1')\n",
    "\n",
    "print('\\nSmina score and energy features successfully merged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68891212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
