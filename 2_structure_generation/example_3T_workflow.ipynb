{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd151a46",
   "metadata": {},
   "source": [
    "# Check / Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fdca277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'subprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-883f6cf0dd8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# GROMACS dependency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mgmx_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'which gmx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mgmx_exec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gromacs/bin/gmx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subprocess' is not defined"
     ]
    }
   ],
   "source": [
    "# It is best to get all of these packages installed in your conda environment before running this notebook.\n",
    "\n",
    "# Python dependencies\n",
    "import os, sys\n",
    "import subprocess\n",
    "import numpy\n",
    "import parmed\n",
    "import six\n",
    "import torch\n",
    "import bs4\n",
    "import mechanize\n",
    "import psutil\n",
    "import ase\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# InterMol installation\n",
    "os.chdir(os.path.join('Convert_Gromacs_LAMMPS','InterMol'))\n",
    "os.system('python setup.py build')\n",
    "os.system('python setup.py install')\n",
    "os.chdir(os.path.join('..','..'))\n",
    "\n",
    "# GROMACS dependency\n",
    "gmx_exec = subprocess.check_output('which gmx', shell=True).decode()[:-1]\n",
    "assert gmx_exec.endswith('gromacs/bin/gmx')\n",
    "\n",
    "# Flag\n",
    "dependencies = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c496579d",
   "metadata": {},
   "source": [
    "# Baseline Protein Energy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c059ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we will convert the baseline standalone protein structures (*.pdb) into GROMACS format and \n",
    "## then converted into LAMMPS format. We will then perform a single-snapshot energy calculation using 3T model.\n",
    "## This helps us ensure that the necessary libraries are installed correctly (GROMACS, InterMol, PyTorch) for 3T.\n",
    "## However, there is no ligand force field parametrization in this step (SwissParam webserver),\n",
    "## so that functionality can only be tested in subsequent steps.\n",
    "## The input structure preparation (GROMACS, LAMMPS) may take several minutes.\n",
    "## On a GPU machine, the 3T energy calculation step should be instantenous.\n",
    "\n",
    "assert (dependencies==True)\n",
    "\n",
    "from convert_baseline import calculate_baseline\n",
    "calculate_baseline('1fin_ENS_dH')\n",
    "calculate_baseline('1uyg_ENS')\n",
    "calculate_baseline('1ezq_ENS_dH')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb2c7b2",
   "metadata": {},
   "source": [
    "# Input File Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In 2022, it is computationally unwise to repeat the entire paper's structure generation on a single machine.\n",
    "## In this example, we will pick one ligand for each of the 3 proteins and generate protein-ligand pocket\n",
    "## complex geometries for these 3 protein-ligand pairs.\n",
    "\n",
    "# First, we need to extract the folders containing ALL the ligand input files used in the paper.\n",
    "import os\n",
    "os.chdir('Input_File_Storage')\n",
    "os.system('tar -xf CDK2.tar.gz')\n",
    "os.system('tar -xf HSP90.tar.gz')\n",
    "os.system('tar -xf FXA.tar.gz')\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca72af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next, we will be modest and grab one ligand (*.mol2 and *.rotbond file needed) for each protein.\n",
    "## These ligands' coordinates have previously been docked onto the protein pocket using smina.\n",
    "## These complexes will be our initial structures, equivalent to those generated by standard rigid protein docking.\n",
    "\n",
    "os.system('rm -r Input_Structures/1fin_ENS_dH/Ligands/*')\n",
    "os.system('rm -r Input_Structures/1uyg_ENS/Ligands/*')\n",
    "os.system('rm -r Input_Structures/1ezq_ENS_dH/Ligands/*')\n",
    "\n",
    "inp = 'Input_File_Storage/CDK2/cocry_2iw8_4SP_LIG_dock_1FIN_1'\n",
    "outp = 'Input_Structures/1fin_ENS_dH/Ligands/CDK2_dock/'\n",
    "os.system('mkdir '+outp)\n",
    "os.system('cp '+inp+'* '+outp)\n",
    "\n",
    "inp = 'Input_File_Storage/HSP90/cocry_2fwy_H64_LIG_dock_1uyg_1'\n",
    "outp = 'Input_Structures/1uyg_ENS/Ligands/HSP90_dock/'\n",
    "os.system('mkdir '+outp)\n",
    "os.system('cp '+inp+'* '+outp)\n",
    "\n",
    "inp = 'Input_File_Storage/FXA/cocry_2d1j_D01_LIG_dock_1ezq_1'\n",
    "outp = 'Input_Structures/1ezq_ENS_dH/Ligands/FXA_dock/'\n",
    "os.system('mkdir '+outp)\n",
    "os.system('cp '+inp+'* '+outp)\n",
    "\n",
    "\n",
    "## If you want to run the entire ligand sets on a single machine (not recommended), uncomment this block:\n",
    "##inp = 'Input_File_Storage/CDK2/'\n",
    "##outp = 'Input_Structures/1fin_ENS_dH/Ligands/CDK2_dock/'\n",
    "##os.system('mkdir '+outp)\n",
    "##os.system('cp '+inp+'* '+outp)\n",
    "##inp = 'Input_File_Storage/HSP90/'\n",
    "##outp = 'Input_Structures/1uyg_ENS/Ligands/HSP90_dock/'\n",
    "##os.system('mkdir '+outp)\n",
    "##os.system('cp '+inp+'* '+outp)\n",
    "##inp = 'Input_File_Storage/FXA/'\n",
    "##outp = 'Input_Structures/1ezq_ENS_dH/Ligands/FXA_dock/'\n",
    "##os.system('mkdir '+outp)\n",
    "##os.system('cp '+inp+'* '+outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e46e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will also choose our 3T generation hyperparameters. On 1 NVIDIA T4 GPU, generating 1 protein-ligand complex\n",
    "## conformation takes around 12 minutes on average. On 1 NVIDIA V100 GPU, it should be >2x faster.\n",
    "## On a 64-core CPU, it takes 2 hours & 45 minutes to generate 64 conformations in parallel. You should budget this\n",
    "## example testing based on your own computation resources. We will proceed with generating\n",
    "## only 1 conformation / protein. This may take 36-45 minute on a low-end GPU like T4, or 9 hours on single-core CPU.\n",
    "config_folder = 'Config_Files/Short_Test_Configs/'\n",
    "\n",
    "## If you have sufficiently good GPU and would like 10 conformations per complex instead, uncomment this line:\n",
    "##config_folder = 'Config_Files/Paper_Configs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1285efc",
   "metadata": {},
   "source": [
    "# Ligand Force Field Parametrization & 3T Structure Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_folder(path1):\n",
    "    dirs = os.listdir(path1)\n",
    "    for dir_ in dirs:\n",
    "        path2 = os.path.join(path1,dir_)\n",
    "        if os.path.isdir(path2):\n",
    "            dirs2 = os.listdir(path2)\n",
    "            for dir2_ in dirs2:\n",
    "                full_path = os.path.join(path2,dir2_)\n",
    "                if os.path.isdir(full_path):\n",
    "                    os.system('rm -r '+full_path)\n",
    "\n",
    "## Uncomment the block below if you want to clean up the 'Converted_Structures' and 'Minimized_Structures' folders.\n",
    "## We recommend cleaning up if you are starting a fresh run, and commenting these out if your session crashes due\n",
    "## to external problems and would like to continue from where you left off.\n",
    "\n",
    "cleanup_folder('Converted_Structures')\n",
    "cleanup_folder('Minimized_Structures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ef2aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we will call exec_workflow.py. This script takes a json config file, which specifies the base protein to run,\n",
    "## as well as other structure generation settings (kick strength, # of conformations, etc). Check the 'Config_Files'\n",
    "## folder for more detail.\n",
    "## The behavior of exec_workflow.py depends on the machine being used. On a GPU machine, it is a single-process code.\n",
    "## On an n-core CPU machine, it is an n-processes code simultaneously working on n different ligands. All ligands \n",
    "## within the baseline protein folder in the 'Input_Structures' folder will be processed, and split between the \n",
    "## processes. Each process will then generate the required # of structure conformations, based on \n",
    "## the random number seeds being used.\n",
    "## We also ensure that completed tasks are not repeated. If the output files for each step (force field assignment,\n",
    "## ligand relaxation, pocket relaxation) are detected, the corresponding step will be skipped. This is useful for\n",
    "## large scale structure generation. \n",
    "\n",
    "assert (dependencies==True)\n",
    "from exec_workflow import main as main_exec\n",
    "\n",
    "## We strongly recommend the usage of a GPU machine, but a CPU machine will work just fine (several hours longer).\n",
    "## We will run these structure generations one by one.\n",
    "main_exec(config_folder+'CDK2.json')\n",
    "main_exec(config_folder+'HSP90.json')\n",
    "main_exec(config_folder+'FXA.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790100ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## At this point, the generates structures will be located in the 'Minimized_Structures' folder.\n",
    "\n",
    "print('Generated CDK2 protein-ligand complex folders:')\n",
    "name = 'Minimized_Structures/1fin_ENS_dH/CDK2_dock/'\n",
    "print(name), print(os.listdir(name)), print('')\n",
    "\n",
    "print('Generated HSP90 protein-ligand complex folders:')\n",
    "name = 'Minimized_Structures/1uyg_ENS/HSP90_dock/'\n",
    "print(name), print(os.listdir(name)), print('')\n",
    "\n",
    "print('Generated FXA protein-ligand complex folders:')\n",
    "name = 'Minimized_Structures/1ezq_ENS_dH/FXA_dock/'\n",
    "print(name), print(os.listdir(name)), print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f2af32",
   "metadata": {},
   "source": [
    "# Compile Energy Values into Classifier Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddf294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def load_last_E(E_file):\n",
    "    with open(E_file,'r') as f:\n",
    "        return float(f.read().strip().split('\\n')[-1])\n",
    "    \n",
    "def process_complex_E(E_file, lig_E, pro_E):\n",
    "    with open(E_file,'r') as f:\n",
    "        out = [float(line)-lig_E-pro_E for line in f.read().strip().split('\\n')]\n",
    "    return np.array(out)\n",
    "\n",
    "def compile_E(pro_tag, out_tag):\n",
    "    pro_E_file = os.path.join('Converted_Structures',pro_tag,'PRO_outE.txt')\n",
    "    pro_E = load_last_E(pro_E_file)\n",
    "    min_dir = os.path.join('Minimized_Structures',pro_tag)\n",
    "    dock_dirs = os.listdir(min_dir)\n",
    "    assert len(dock_dirs)==1\n",
    "    lig_dirs = os.listdir( os.path.join(min_dir, dock_dirs[0]) )\n",
    "    seed_dict = None\n",
    "    E_curves = None\n",
    "    complex_list = []\n",
    "    seed_list = []\n",
    "    for i, lig_dir in enumerate(lig_dirs):\n",
    "        lig_dir = os.path.join(min_dir, dock_dirs[0], lig_dir)\n",
    "        files = os.listdir(lig_dir)\n",
    "        lig_E_files = [_ for _ in files if _.startswith('LIG') and _.endswith('outE.txt')]\n",
    "        assert len(lig_E_files)==1\n",
    "        lig_E = load_last_E( os.path.join(lig_dir, lig_E_files[0]) )\n",
    "        E_files = [_ for _ in files if _.startswith('stepAll') and _.endswith('outE.txt')]\n",
    "        if seed_dict is None:\n",
    "            seed_dict = dict()\n",
    "            for E_file in E_files:\n",
    "                seed = E_file.split('_')[-2]\n",
    "                seed_dict[seed] = len(seed_dict)\n",
    "                seed_list.append(seed)\n",
    "        for E_file in E_files:\n",
    "            seed = E_file.split('_')[-2]\n",
    "            E_array = process_complex_E( os.path.join(lig_dir,E_file), lig_E, pro_E)\n",
    "            if E_curves is None:\n",
    "                E_curves = np.zeros([len(lig_dirs), len(seed_dict), len(E_array)])\n",
    "            E_curves[i, seed_dict[seed]] = E_array\n",
    "        complex_list.append( os.path.split(lig_dir)[-1] )\n",
    "    out_dict = dict()\n",
    "    out_dict['complex'] = complex_list\n",
    "    out_dict['E_binding'] = E_curves / 1000\n",
    "    out_dict['seed'] = seed_list\n",
    "    pickle.dump(out_dict, open( os.path.join('Energies',out_tag+'_3T_energy.pkl'), 'wb'))\n",
    "    return\n",
    "\n",
    "## We will simply compile the corresponding energy landscape for each protein-ligand complex conformation,\n",
    "## to be used in subsequent active ligand classification step.\n",
    "compile_E('1fin_ENS_dH', 'CDK2')\n",
    "compile_E('1uyg_ENS', 'HSP90')\n",
    "compile_E('1ezq_ENS_dH', 'FXA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7df3b8",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e945a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To visualize the generated protein-ligand complex conformations you have just generated, you will need\n",
    "## software like VMD or PyMol. You will find the following files in the protein-ligand complex folders from above:\n",
    "## - Initial docked structure: Converted_Structures/[protein_code]/[protein]_dock/[ligand_code]/complex.gro\n",
    "## - Relaxed ligand structure: Minimized_Structures/[protein_code]/[protein]_dock/[ligand_code]/step1_[ligand_epoch].xyz\n",
    "## - Relaxed pocket structure: Minimized_Structures/[protein_code]/[protein]_dock/[ligand_code]/step2_*_[kick_random_seed].xyz\n",
    "##\n",
    "## Here we show you the 10 conformations generated for each of the 3 protein-ligand complexes from the above example,\n",
    "## with the ligands removed from the image for clarity. These are what you will get if you have set \n",
    "## config_folder = 'Config_Files/Paper_Configs/'\n",
    "## in the configuration file selection above, instead of the lower-cost 'Config_Files/Short_Test_Configs/' version.\n",
    "## Feel free to visualize the structures you have personally generated above using your favorite visualization tools.\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print('Display 10 conformations for:')\n",
    "\n",
    "print('CDK2 complex (1fin_2iw8-4SP)')\n",
    "im1 = Image(filename = os.path.join('Images','CDK2_1fin_2iw8-4SP.png'))\n",
    "\n",
    "print('HSP90 complex (1uyg_2fwy-H64)')\n",
    "im2 = Image(filename = os.path.join('Images','HSP90_1uyg_2fwy-H64.png'))\n",
    "\n",
    "print('FXA complex (1ezq_2d1j-D01)')\n",
    "im3 = Image(filename = os.path.join('Images','FXA_1ezq_2d1j-D01.png'))\n",
    "\n",
    "display(im1, im2, im3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a051e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
